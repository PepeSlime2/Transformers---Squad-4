## Guia rÃ¡pido

Siga estes passos para rodar o benchmark leve no seu notebook.

1) Criar ambiente virtual e ativar
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

2) Instalar dependÃªncias
```powershell
pip install -r requirements.txt
```

3) Rodar benchmark leve
```powershell
python benchmark_lite.py
```

4) Visualizar resultados (opcional)
```powershell
mlflow ui --host 127.0.0.1 --port 5001
```
Abra: http://127.0.0.1:5001

Restaurar backup (se necessÃ¡rio)
```powershell
Expand-Archive -Path restore_files.zip -DestinationPath . -Force
```

Se precisar de instruÃ§Ãµes mais detalhadas, consulte o `README.md`.

```markdown
# Guia RÃ¡pido de InstalaÃ§Ã£o e Uso

Este guia leva vocÃª do zero atÃ© rodar um benchmark rÃ¡pido.

PrÃ©-requisitos
- Python 3.10+ instalado
- Internet para baixar modelos e datasets

1) Criar e ativar ambiente virtual
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

2) Instalar dependÃªncias
```powershell
pip install -r requirements.txt
```

3) Executar benchmark leve
```powershell
python benchmark_lite.py
```
- O script salva um CSV com os resultados no diretÃ³rio atual e grava metadados no `mlruns/`.

4) Visualizar resultados
```powershell
mlflow ui --host 127.0.0.1 --port 5001
```
Abra no navegador: http://127.0.0.1:5001

Dicas rÃ¡pidas
- Se estiver sem GPU: use `benchmark_lite.py`.
- Para liberar espaÃ§o: remova `restore_files.zip` ou o diretÃ³rio `venv/` quando nÃ£o precisar.
- Para restaurar arquivos removidos: `Expand-Archive -Path restore_files.zip -DestinationPath .`.

Se precisar de instruÃ§Ãµes passo-a-passo mais detalhadas, consulte o `README.md`.

```markdown
# ğŸš€ Guia RÃ¡pido de InÃ­cio (VersÃ£o Simplificada)

## âš¡ Objetivo

Este repositÃ³rio foi reduzido para o conjunto mÃ­nimo necessÃ¡rio para executar benchmarks leves de modelos Transformer (versÃ£o "lite"). O script principal agora Ã© `benchmark_lite.py`.

## âš™ï¸ O que estÃ¡ neste repositÃ³rio (essencial)
- `benchmark_lite.py` â€” Script principal que executa os benchmarks (inference-only para hardware limitado).
- `requirements.txt` â€” DependÃªncias Python.
- `README.md` â€” DocumentaÃ§Ã£o rÃ¡pida e detalhes.
- `agricultural_data.py` â€” Dados de exemplo/sintÃ©ticos.
- `mlruns/` â€” Logs do MLflow (nÃ£o removido).
- `restore_files.zip` â€” Backup dos arquivos removidos (caso queira restaurar).

## ğŸ’» Setup RÃ¡pido

Abra PowerShell e crie um venv (recomendado):
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

Se tiver GPU NVIDIA/CUDA, instale a versÃ£o do PyTorch com CUDA (opcional):
```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## â–¶ï¸ Executar o benchmark (versÃ£o lite)
```powershell
python benchmark_lite.py
```
- SaÃ­das: CSV com resultados `benchmark_lite_YYYYMMDD_HHMMSS.csv`.
- Logs de experimento: `mlruns/` (use MLflow UI para visualizar).

## ğŸ“Š Visualizar resultados (MLflow)
```powershell
mlflow ui --host 127.0.0.1 --port 5001
```
Acesse: http://127.0.0.1:5001

> Dica: Para abrir o MLflow UI em background (nova janela do PowerShell):
```powershell
Start-Process powershell -ArgumentList '-NoExit','-Command','mlflow ui --host 127.0.0.1 --port 5001'
```

## ğŸ’¾ RestauraÃ§Ã£o (caso precise dos arquivos removidos)
O arquivo `restore_files.zip` contÃ©m os arquivos antigos que foram removidos durante a limpeza. Para restaurar:
```powershell
Expand-Archive -Path restore_files.zip -DestinationPath . -Force
```

## ğŸ§° Comandos Ãºteis
- Abrir CSV em Python:
```powershell
python -c "import pandas as pd; print(pd.read_csv('benchmark_lite_20251124_114149.csv').head())"
```
- Visualizar imagem do grÃ¡fico (se houver):
```powershell
ii .\benchmark_comparison_20251124_121716.png
```

---
**ObservaÃ§Ã£o**: `benchmark_lite.py` foi ajustado para usar apenas pipelines de inferÃªncia (evita `Trainer`/`accelerate`) para reduzir tempo e dependÃªncias.

```markdown
# ğŸš€ Guia RÃ¡pido de InÃ­cio

## âš¡ Setup RÃ¡pido (2 minutos)

### OpÃ§Ã£o 1: InstalaÃ§Ã£o AutomÃ¡tica (Recomendado)

```powershell
# Execute o script de configuraÃ§Ã£o
.\setup.ps1
```

### OpÃ§Ã£o 2: InstalaÃ§Ã£o Manual

```powershell
# 1. Criar ambiente virtual
python -m venv venv
.\venv\Scripts\Activate.ps1

# 2. Instalar dependÃªncias
pip install -r requirements.txt

# 3. Instalar PyTorch (escolha uma opÃ§Ã£o)

# Com GPU NVIDIA:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Sem GPU (CPU):
pip install torch torchvision torchaudio
```

## ğŸƒ Executar Benchmark

### Para notebooks com MEMÃ“RIA LIMITADA (< 8GB RAM):

```powershell
python benchmark_lite.py
```

â±ï¸ **Tempo estimado**: 5-10 minutos  
ğŸ’¾ **MemÃ³ria necessÃ¡ria**: ~4GB RAM  
ğŸ“Š **Modelos testados**: DistilBERT + DistilGPT2

### Para notebooks com BOA MEMÃ“RIA (8GB+ RAM):

```powershell
python benchmark_transformers_sb100.py
```

â±ï¸ **Tempo estimado**: 20-40 minutos  
ğŸ’¾ **MemÃ³ria necessÃ¡ria**: ~8GB RAM (16GB recomendado)  
ğŸ“Š **Modelos testados**: BERT + GPT-2 + BART + DistilBERT + DistilGPT2

## ğŸ“Š Visualizar Resultados

### 1. Ver arquivo CSV

Os resultados sÃ£o salvos automaticamente em:
- `benchmark_results_YYYYMMDD_HHMMSS.csv` (versÃ£o completa)
- `benchmark_lite_YYYYMMDD_HHMMSS.csv` (versÃ£o lite)

### 2. MLflow UI (Interface Visual)

```powershell
mlflow ui
```

Depois acesse no navegador: **http://localhost:5000**

## ğŸ¯ Qual versÃ£o usar?

| Seu Hardware | Script Recomendado | Tempo | Modelos |
|--------------|-------------------|-------|---------|
| RAM < 8GB | `benchmark_lite.py` | ~5-10min | 2 modelos leves |
| RAM 8-16GB | `benchmark_transformers_sb100.py` | ~20-30min | 5 modelos |
| RAM > 16GB + GPU | `benchmark_transformers_sb100.py` | ~15-20min | 5 modelos |

## ğŸ”§ Problemas Comuns

### âŒ "CUDA out of memory"

**SoluÃ§Ã£o**: Use `benchmark_lite.py` ou feche outros programas

### âŒ "Connection error" ao baixar datasets

**SoluÃ§Ã£o**: Verifique sua conexÃ£o com a internet. Os datasets sÃ£o baixados automaticamente do Hugging Face.

### âŒ MLflow nÃ£o abre

**SoluÃ§Ã£o**: 
```powershell
# Tente porta alternativa
mlflow ui --port 5001
```

## ğŸ“ˆ Interpretando Resultados

### Modelos de ClassificaÃ§Ã£o (BERT/DistilBERT)

- **AcurÃ¡cia**: % de acertos (quanto maior, melhor)
  - Excelente: > 0.90
  - Bom: 0.80 - 0.90
  - RazoÃ¡vel: < 0.80

- **F1-Score**: EquilÃ­brio entre precisÃ£o e recall
  - Excelente: > 0.85
  - Bom: 0.70 - 0.85

### Modelos Generativos (GPT-2/DistilGPT2/BART)

- **Perplexidade**: Incerteza do modelo (quanto menor, melhor)
  - Excelente: < 20
  - Bom: 20 - 40
  - RazoÃ¡vel: > 40

- **BLEU/ROUGE**: Qualidade do texto gerado (quanto maior, melhor)
  - Excelente: > 0.30
  - Bom: 0.15 - 0.30

## ğŸ“ Estrutura dos Arquivos

```
transformer_test/
â”œâ”€â”€ benchmark_transformers_sb100.py  â­ Script completo
â”œâ”€â”€ benchmark_lite.py                âš¡ Script leve
â”œâ”€â”€ setup.ps1                        ğŸ”§ InstalaÃ§Ã£o automÃ¡tica
â”œâ”€â”€ requirements.txt                 ğŸ“¦ DependÃªncias
â”œâ”€â”€ README.md                        ğŸ“š DocumentaÃ§Ã£o completa
â”œâ”€â”€ QUICKSTART.md                    ğŸš€ Este arquivo
â””â”€â”€ mlruns/                          ğŸ’¾ Resultados MLflow
```

## ğŸ’¡ Dicas

1. **Primeira vez?** â†’ Use `benchmark_lite.py`
2. **Quer comparar todos os modelos?** â†’ Use `benchmark_transformers_sb100.py`
3. **Notebook lento/travando?** â†’ Feche outros programas e use versÃ£o lite
4. **Resultados no MLflow** â†’ Melhor visualizaÃ§Ã£o dos experimentos

## ğŸ†˜ Precisa de Ajuda?

Consulte o **README.md** para documentaÃ§Ã£o completa, incluindo:
- ExplicaÃ§Ã£o detalhada das mÃ©tricas
- ConfiguraÃ§Ã£o avanÃ§ada
- SoluÃ§Ã£o de problemas
- ReferÃªncias tÃ©cnicas

---

**Boa sorte com seus benchmarks! ğŸ‰**
