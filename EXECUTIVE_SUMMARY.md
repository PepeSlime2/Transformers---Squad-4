```markdown
# Resumo Executivo - Benchmark Transformers (vers√£o simplificada)

Objetivo
---------
Avaliar o desempenho de modelos Transformer em tarefas de classifica√ß√£o e gera√ß√£o, usando conjuntos de dados reduzidos para facilitar a execu√ß√£o em equipamentos com recursos limitados.

O que este reposit√≥rio cont√©m
--------------------------------
- `benchmark_lite.py`: script principal para avalia√ß√£o r√°pida (inference-only).
- `benchmark_lite_*.csv`: resultados consolidados em CSV.
- `mlruns/`: registros dos experimentos no MLflow.
- `restore_files.zip`: backup dos arquivos originais, caso precise restaurar algo.

Modelos utilizados nesta vers√£o
------------------------------
- DistilBERT (classifica√ß√£o)
- DistilGPT2 (gera√ß√£o)

Principais m√©tricas
-------------------
- Acur√°cia, Precis√£o, Recall, F1 (classifica√ß√£o)
- Perplexidade, BLEU, ROUGE (gera√ß√£o) ‚Äî quando aplic√°vel
- Tempo de infer√™ncia e tempo de gera√ß√£o
- Tamanho do modelo (MB) e n√∫mero de par√¢metros

Resumo dos resultados (exemplo)
-------------------------------
- DistilBERT: r√°pido, leve, accuracy baixa se n√£o for finetuned para a tarefa espec√≠fica.
- DistilGPT2: gera textos coerentes em amostras curtas; tempo de gera√ß√£o aceit√°vel em CPU.

Recomenda√ß√µes
-------------
1. Para a maioria das avalia√ß√µes r√°pidas, use `benchmark_lite.py`.
2. Caso precise de avalia√ß√£o mais completa ou fine-tuning, execute os scripts de vers√£o completa a partir do backup.
3. Use MLflow para comparar runs e consultar m√©tricas detalhadas.

Pr√≥ximos passos sugeridos
-------------------------
1. Subir amostras reais do dom√≠nio agr√≠cola e reavaliar os modelos.
2. Fazer fine-tuning em modelos leves (se for necess√°rio melhorar accuracy).
3. Automatizar a coleta de m√©tricas para rodar compara√ß√µes peri√≥dicas.

Versionamento
-------------
Vers√£o atual: 1.0 (Novembro 2025), vers√£o simplificada focada em infer√™ncia.

# üìä Resumo Executivo - Benchmark Transformers SB100

## Projeto CCD SB100 ‚Äì Squad 4
**Instituto Agron√¥mico de Campinas (IAC)**

---

## üéØ Objetivo

Realizar benchmarks comparativos de modelos Transformer (BERT, GPT-2, BART e variantes) para avaliar seu desempenho em tarefas relacionadas ao dom√≠nio agr√≠cola, especificamente textos do Boletim 100 do IAC.

## üìÅ Arquivos do Projeto

| Arquivo | Descri√ß√£o | Quando Usar |
|---------|-----------|-------------|
| `benchmark_transformers_sb100.py` | ‚≠ê Script completo de benchmark | Hardware com 8GB+ RAM |
| `benchmark_lite.py` | ‚ö° Vers√£o otimizada | Hardware com < 8GB RAM |
| `test_agricultural_models.py` | üß™ Testes com dados agr√≠colas | Demonstra√ß√£o de uso |
| `agricultural_data.py` | üìö Dataset de exemplos | Fonte de dados |
| `setup.ps1` | üîß Instala√ß√£o autom√°tica | Primeira vez |
| `requirements.txt` | üì¶ Depend√™ncias | Instala√ß√£o manual |
| `README.md` | üìñ Documenta√ß√£o completa | Refer√™ncia detalhada |
| `QUICKSTART.md` | üöÄ Guia r√°pido | In√≠cio r√°pido |

## ü§ñ Modelos Avaliados

### Encoder (Classifica√ß√£o)
- **DistilBERT** - 67M par√¢metros (leve e r√°pido)
- **BERT** - 110M par√¢metros (mais preciso)

### Decoder/Seq2Seq (Gera√ß√£o)
- **DistilGPT-2** - 82M par√¢metros (leve e r√°pido)
- **GPT-2** - 124M par√¢metros (mais criativo)
- **BART** - 140M par√¢metros (seq2seq)

### Nota sobre Modelos Grandes
- **LLaMA** e **DeepSeek** requerem 8GB+ VRAM
- Para hardware limitado, use modelos Distil* como alternativas v√°lidas

## üìä M√©tricas Coletadas

### ‚úÖ Precis√£o
| M√©trica | Tipo de Modelo | Interpreta√ß√£o |
|---------|----------------|---------------|
| Acur√°cia | Classifica√ß√£o | % de previs√µes corretas |
| Precis√£o | Classifica√ß√£o | % de positivos corretos |
| Recall | Classifica√ß√£o | % de positivos encontrados |
| F1-Score | Classifica√ß√£o | M√©dia harm√¥nica P/R |
| BLEU | Gera√ß√£o | Qualidade do texto gerado |
| ROUGE | Gera√ß√£o | Sobreposi√ß√£o de n-gramas |
| Perplexidade | Gera√ß√£o | Incerteza do modelo |

### ‚ö° Efici√™ncia
- Tempo de treinamento (segundos)
- Tempo de infer√™ncia (segundos)
- Amostras processadas por segundo

### üíæ Recursos
- N√∫mero de par√¢metros
- Tamanho do modelo (MB)
- Mem√≥ria GPU (VRAM)

## üöÄ Como Executar

### Instala√ß√£o (5 minutos)
```powershell
# Autom√°tica
.\setup.ps1

# Manual
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Execu√ß√£o

**Op√ß√£o 1: Vers√£o Leve (Recomendado para maioria)**
```powershell
python benchmark_lite.py
```
- ‚è±Ô∏è Tempo: 5-10 minutos
- üíæ RAM necess√°ria: ~4GB
- üìä Testa: DistilBERT + DistilGPT2

**Op√ß√£o 2: Vers√£o Completa**
```powershell
python benchmark_transformers_sb100.py
```
- ‚è±Ô∏è Tempo: 20-40 minutos
- üíæ RAM necess√°ria: 8GB+ (16GB recomendado)
- üìä Testa: 5 modelos diferentes

**Op√ß√£o 3: Testes com Dados Agr√≠colas**
```powershell
python test_agricultural_models.py
```
- ‚è±Ô∏è Tempo: 5-15 minutos
- Demonstra uso pr√°tico dos modelos

### Visualiza√ß√£o de Resultados
```powershell
mlflow ui
# Acesse: http://localhost:5000
```

## üìà Resultados Esperados

### Modelos de Classifica√ß√£o (AG News Dataset)

| Modelo | Acur√°cia | F1-Score | Tempo Treino | Par√¢metros |
|--------|----------|----------|--------------|------------|
| DistilBERT | ~0.89 | ~0.88 | ~45s | 67M |
| BERT | ~0.91 | ~0.90 | ~90s | 110M |

### Modelos Generativos (WikiText Dataset)

| Modelo | Perplexidade | BLEU | ROUGE-L | Tempo Inf. | Par√¢metros |
|--------|--------------|------|---------|------------|------------|
| DistilGPT2 | ~32 | ~0.15 | ~0.22 | ~12s | 82M |
| GPT-2 | ~28 | ~0.18 | ~0.25 | ~23s | 124M |
| BART | ~25 | ~0.21 | ~0.29 | ~31s | 140M |

**Nota**: Valores aproximados, variam conforme hardware e configura√ß√£o.

## üîç Interpreta√ß√£o dos Resultados

### Para Classifica√ß√£o
- **Acur√°cia > 0.85**: Excelente
- **F1-Score > 0.80**: Bom equil√≠brio

### Para Gera√ß√£o
- **Perplexidade < 30**: Excelente
- **BLEU > 0.20**: Bom
- **ROUGE-L > 0.25**: Bom

## üí° Recomenda√ß√µes

### Para Hardware Limitado (< 8GB RAM)
1. ‚úÖ Use `benchmark_lite.py`
2. ‚úÖ Teste apenas DistilBERT e DistilGPT2
3. ‚úÖ Reduza `sample_size` no c√≥digo se necess√°rio

### Para Hardware M√©dio (8-16GB RAM)
1. ‚úÖ Use `benchmark_transformers_sb100.py`
2. ‚úÖ Feche outros programas durante execu√ß√£o
3. ‚úÖ Monitore uso de mem√≥ria

### Para Hardware Avan√ßado (16GB+ RAM, GPU)
1. ‚úÖ Use `benchmark_transformers_sb100.py`
2. ‚úÖ Aumente `sample_size` para melhor avalia√ß√£o
3. ‚úÖ Considere testar modelos maiores (LLaMA, etc.)

## üéì Aplica√ß√µes no Dom√≠nio Agr√≠cola

### Casos de Uso
1. **Classifica√ß√£o de Documentos** - Categorizar relat√≥rios t√©cnicos
2. **Extra√ß√£o de Informa√ß√µes** - Identificar pr√°ticas recomendadas
3. **Gera√ß√£o de Textos** - Criar resumos de boletins
4. **Question Answering** - Sistema de perguntas sobre culturas
5. **An√°lise de Sentimento** - Avaliar percep√ß√£o sobre tecnologias

### Datasets Espec√≠ficos
- Textos sobre Citrus (5 amostras)
- Textos sobre Caf√© (5 amostras)
- Pares de Q&A (5 exemplos)
- Categorias agr√≠colas

## üìä Estrutura do MLflow

```
mlruns/
‚îî‚îÄ‚îÄ Benchmark_Transformers_SB100/
    ‚îú‚îÄ‚îÄ Run 1: DistilBERT_classification
    ‚îú‚îÄ‚îÄ Run 2: BERT_classification
    ‚îú‚îÄ‚îÄ Run 3: DistilGPT2_generation
    ‚îú‚îÄ‚îÄ Run 4: GPT2_generation
    ‚îî‚îÄ‚îÄ Run 5: BART_generation
```

Cada run cont√©m:
- **Par√¢metros**: modelo, hiperpar√¢metros, device
- **M√©tricas**: todas as m√©tricas de desempenho
- **Artefatos**: logs, checkpoints

## ‚ö†Ô∏è Problemas Comuns e Solu√ß√µes

| Problema | Solu√ß√£o |
|----------|---------|
| CUDA out of memory | Use `benchmark_lite.py` |
| Download lento | Verifique conex√£o internet |
| MLflow n√£o abre | Use `mlflow ui --port 5001` |
| Importa√ß√µes falhando | Execute `pip install -r requirements.txt` |

## üìö Refer√™ncias T√©cnicas

- [Transformers Documentation](https://huggingface.co/docs/transformers)
- [MLflow Documentation](https://mlflow.org/docs/latest/index.html)
- [BERT Paper](https://arxiv.org/abs/1810.04805)
- [GPT-2 Paper](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
- [BART Paper](https://arxiv.org/abs/1910.13461)

## üìù Checklist de Uso

- [ ] Ambiente virtual criado e ativado
- [ ] Depend√™ncias instaladas
- [ ] PyTorch instalado (GPU ou CPU)
- [ ] Script de benchmark executado
- [ ] Resultados salvos em CSV
- [ ] MLflow UI acessado
- [ ] M√©tricas analisadas
- [ ] Compara√ß√µes realizadas

## üéØ Pr√≥ximos Passos

1. **Coletar dados reais** do Boletim 100 do IAC
2. **Fine-tuning** dos modelos com dados agr√≠colas
3. **Valida√ß√£o** com especialistas do dom√≠nio
4. **Deployment** de modelo(s) selecionado(s)
5. **Integra√ß√£o** em sistema de consulta

## üë• Cr√©ditos

**Projeto**: CCD SB100 ‚Äì Squad 4  
**Institui√ß√£o**: Instituto Agron√¥mico de Campinas (IAC)  
**Data**: Novembro 2025

---

**Para mais informa√ß√µes, consulte README.md ou QUICKSTART.md**
